{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lecture 2: Naive Bayes\n",
    "***\n",
    "\n",
    "<img src=\"files/figs/bayes.jpg\",width=1201,height=50> \n",
    "\n",
    "<!---\n",
    "![my_image](files/figs/bayes.jpg)\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prob1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Bayes Law and The Monte Hall Problem \n",
    "***\n",
    "\n",
    "\n",
    ">Suppose you're on a game show, and you're given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what's behind the doors, opens another door, say No. 3, which has a goat. He then says to you, \"Do you want to pick door No. 2?\" Is it to your advantage to switch your choice?\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Monty_open_door.svg/2000px-Monty_open_door.svg.png\",width=801,height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: What does your intuition say?  Is it in your best interest to switch? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B**: Use Bayes Rule to compute that your probability of winning if you switch and if you do not switch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prob2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Naive Bayes on Symbols\n",
    "***\n",
    "\n",
    "> This problem was adopted from [Naive Bayes and Text Classification I: Introduction and Theory](https://arxiv.org/abs/1410.5329) by Sebastian Raschka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following training set of 12 symbols which have been labeled as either + or -: \n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"files/figs/shapes.png?raw=true\"; width=500>\n",
    "\n",
    "<!---\n",
    "![](files/figs/shapes.png?raw=true)\n",
    "-->\n",
    "\n",
    "Answer the following questions: \n",
    "\n",
    "\n",
    "**A**: What are the general features associated with each training example? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part, we'll use Naive Bayes to classify the following test example: \n",
    "\n",
    "<img src=\"files/figs/bluesquare.png\"; width=200>\n",
    "\n",
    "OK, so this symbol actually appears in the training set, but let's pretend that it doesn't.  \n",
    "\n",
    "The decision rule can be defined as \n",
    "\n",
    ">Classify ${\\bf x}$ as + if <br>\n",
    ">$p(+ ~|~ {\\bf x} = [blue,~ square]) \\geq p(- ~|~ {\\bf x} = [blue, ~square])$ <br>\n",
    ">else classify sample as -\n",
    "\n",
    "**B**: What are the Maximum Likelihood Estimates of the priors $p(+)$ and $p(-)$? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C**: Identify and compute estimates of the class-conditional probabilities required to predict the class of ${\\bf x} = [blue,~square]$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D**: Using the estimates computed above, compute the **posterior** scores for each label, and find the Naive Bayes prediction of the label for ${\\bf x} = [blue,~square]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E**: If you haven't already, compute the class-conditional probabilities scores $\\hat{p}({\\bf x} = [blue,~square] ~|~ +)$ and $\\hat{p}({\\bf x} = [blue,~square] ~|~ -)$ under the Naive Bayes assumption.  How can you reconsile these values with the final prediction that would made? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prob3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Laplace Smoothing \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the same training set from Problem 2, but suppose we see the following test example: \n",
    "    \n",
    "<img src=\"figs/greencircle.png\"; width=200>\n",
    "\n",
    "Before you get too far into trying to predict the label of the green circle, look carefully at the training set.  Notice that there are no green shapes labeled - in the training set, so when we try to compute the class-conditional probability $p(green ~|~ -)$ we'll get a zero probability.  To fix this, you'll implement Laplace smoothing. Notice that this is a little different than the SPAM vs HAM example shown in the video.  We actually have two very different features in shapes and colors. We'll apply Laplace Smoothing to the shape and color class-conditional probabilities separately. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: What would the general formula for the estimate of $p(shape ~|~ class)$ with Laplace Smoothing look like for the given training set?  What is the *vocabulary* in the shape case?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B**: What would the general formula for the estimate of $p(color ~|~ class)$ with Laplace Smoothing look like for the given training set?  What is the *vocabulary* in the shape case?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C**: Predict the label for the green circle using the Laplaced smoothed class-conditional probability formulas.  Don't forget to apply Laplace Smoothing to the priors as well! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Problem 3 Answers]](#prob3ans)\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prob4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Unknown Features\n",
    "***\n",
    "\n",
    "Once again consider the training set from Problem 2, but suppose we see the following test example: \n",
    "    \n",
    "<img src=\"figs/yellowsquare.png\"; width=200>\n",
    "\n",
    "OK, this is a weird one.  Up until this point, we've never seen the color *yellow*, and thus don't include it in the color vocabulary.  One way that we could handle this is to add to the color vocabulary, and then recompute the the class-conditional probabilities with *yellow* included in the vocabulary. \n",
    "\n",
    "But what happens when on the next test example we see a *pink* circle (or worse, a triangle)? We'd rather not continue to modify our probability estimates whenever we see shape or color that we haven't see before.  One solution to this is to just assume we'll see weird things in the future and combine all of the posibilities into an UNK feature. If we do this, then our class-conditional probabilities become \n",
    "\n",
    "$$\n",
    "p(feature ~|~ class) = \\frac{\\#~instances~of~feature~in~class + 1}{\\#~total~symbols~in~class + |V| + 1}\n",
    "$$\n",
    "\n",
    "where here the vocabular $V$ is the same vocabular defined by the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A**: Predict the label of the yellow square.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prob1ans'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "### Helper Functions \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".MathJax nobr>span.math>span{border-left-width:0 !important};\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
